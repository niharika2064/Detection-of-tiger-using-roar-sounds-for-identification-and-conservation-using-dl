{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_x-jzxNynCD6"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = load_model('/content/drive/MyDrive/ Features_Output/1dcnnmodel.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "model_path = '/content/drive/MyDrive/ Features_Output/1dcnnmodel.h5'  # Replace with your model's path\n",
        "loaded_model = load_model(model_path)\n",
        "\n",
        "# Define a function to extract and preprocess features from a new audio file\n",
        "def extract_and_preprocess_features(audio_path, expected_shape):\n",
        "    try:\n",
        "        # Load the new audio file\n",
        "        audio_data, sample_rate = librosa.load(audio_path, sr=None)\n",
        "\n",
        "        # Extract MFCCs, ZCR, Mel spectrogram, and Chroma features (adjust as needed)\n",
        "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=20)\n",
        "        zcr = librosa.feature.zero_crossing_rate(y=audio_data)\n",
        "        mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
        "        chroma = librosa.feature.chroma_stft(y=audio_data, sr=sample_rate)\n",
        "\n",
        "        # Calculate the mean of each feature\n",
        "        mfcc_mean = np.mean(mfccs, axis=1)\n",
        "        zcr_mean = np.mean(zcr, axis=1)\n",
        "        mel_mean = np.mean(mel_spectrogram, axis=1)\n",
        "        chroma_mean = np.mean(chroma, axis=1)\n",
        "\n",
        "\n",
        "        # Combine the extracted features into a single feature vector\n",
        "        combined_features = np.concatenate((mfcc_mean, zcr_mean, mel_mean, chroma_mean))\n",
        "\n",
        "        # Ensure that the feature vector shape matches the expected shape\n",
        "        if combined_features.shape[0] < expected_shape[0]:\n",
        "            # Pad the feature vector with zeros\n",
        "            padding = np.zeros(expected_shape[0] - combined_features.shape[0])\n",
        "            combined_features = np.concatenate((combined_features, padding))\n",
        "\n",
        "        return combined_features\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Replace 'new_audio_path' with the path to your new audio file\n",
        "new_audio_path = '/content/drive/MyDrive/Animal_Dataset/Birds/bird1.wav'\n",
        "\n",
        "# Define the expected input shape of the model\n",
        "expected_input_shape = (169, 1)  # Update with your model's expected input shape\n",
        "\n",
        "# Extract and preprocess features from the new audio file\n",
        "new_audio_features = extract_and_preprocess_features(new_audio_path, expected_input_shape)\n",
        "\n",
        "if new_audio_features is not None:\n",
        "    # Make predictions using the loaded model\n",
        "    predictions = loaded_model.predict(new_audio_features[np.newaxis, :])\n",
        "\n",
        "    # Get the predicted class labels (assuming it's a classification problem)\n",
        "    predicted_class_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Create a mapping of class codes to class labels\n",
        "    class_label_mapping = {\n",
        "        0: 'Birds',\n",
        "        1: 'Elephant',\n",
        "        2: 'Leopard',\n",
        "        3: 'Otter',\n",
        "        4: 'Tiger'\n",
        "    }\n",
        "\n",
        "    # Map the class code to class label for the predicted class\n",
        "    predicted_class_name = class_label_mapping[predicted_class_labels[0]]\n",
        "\n",
        "    # Print the predicted class label for the new audio file\n",
        "    print(f\"Predicted Class Label for {new_audio_path}: {predicted_class_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qrd12hztc8y",
        "outputId": "44ed0cf7-dbb3-4e32-f6c1-dcfe5fec3d93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 231ms/step\n",
            "Predicted Class Label for /content/drive/MyDrive/Animal_Dataset/Birds/bird1.wav: Birds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "model_path = '/content/drive/MyDrive/ Features_Output/1dcnnmodel.h5'  # Replace with your model's path\n",
        "loaded_model = load_model(model_path)\n",
        "\n",
        "# Define a function to extract and preprocess features from a new audio file\n",
        "def extract_and_preprocess_features(audio_path, expected_shape):\n",
        "    try:\n",
        "        # Load the new audio file\n",
        "        audio_data, sample_rate = librosa.load(audio_path, sr=None)\n",
        "\n",
        "        # Extract MFCCs, ZCR, Mel spectrogram, and Chroma features (adjust as needed)\n",
        "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=20)\n",
        "        zcr = librosa.feature.zero_crossing_rate(y=audio_data)\n",
        "        mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
        "        chroma = librosa.feature.chroma_stft(y=audio_data, sr=sample_rate)\n",
        "\n",
        "        # Calculate the mean of each feature\n",
        "        mfcc_mean = np.mean(mfccs, axis=1)\n",
        "        zcr_mean = np.mean(zcr, axis=1)\n",
        "        mel_mean = np.mean(mel_spectrogram, axis=1)\n",
        "        chroma_mean = np.mean(chroma, axis=1)\n",
        "\n",
        "\n",
        "        # Combine the extracted features into a single feature vector\n",
        "        combined_features = np.concatenate((mfcc_mean, zcr_mean, mel_mean, chroma_mean))\n",
        "\n",
        "        # Ensure that the feature vector shape matches the expected shape\n",
        "        if combined_features.shape[0] < expected_shape[0]:\n",
        "            # Pad the feature vector with zeros\n",
        "            padding = np.zeros(expected_shape[0] - combined_features.shape[0])\n",
        "            combined_features = np.concatenate((combined_features, padding))\n",
        "\n",
        "        return combined_features\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Replace 'new_audio_path' with the path to your new audio file\n",
        "new_audio_path = '/content/drive/MyDrive/Animal_Dataset/Birds/bird3.wav'\n",
        "\n",
        "# Define the expected input shape of the model\n",
        "expected_input_shape = (169, 1)  # Update with your model's expected input shape\n",
        "\n",
        "# Extract and preprocess features from the new audio file\n",
        "new_audio_features = extract_and_preprocess_features(new_audio_path, expected_input_shape)\n",
        "\n",
        "if new_audio_features is not None:\n",
        "    # Make predictions using the loaded model\n",
        "    predictions = loaded_model.predict(new_audio_features[np.newaxis, :])\n",
        "\n",
        "    # Get the predicted class labels (assuming it's a classification problem)\n",
        "    predicted_class_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Create a mapping of class codes to class labels\n",
        "    class_label_mapping = {\n",
        "        0: 'Birds',\n",
        "        1: 'Elephant',\n",
        "        2: 'Leopard',\n",
        "        3: 'Otter',\n",
        "        4: 'Tiger'\n",
        "    }\n",
        "\n",
        "    # Map the class code to class label for the predicted class\n",
        "    predicted_class_name = class_label_mapping[predicted_class_labels[0]]\n",
        "\n",
        "    # Print the predicted class label for the new audio file\n",
        "    print(f\"Predicted Class Label for {new_audio_path}: {predicted_class_name}\")\n"
      ],
      "metadata": {
        "id": "UtDAPnZdxglu",
        "outputId": "6bf618aa-bdf2-48a1-a742-2822e302e06b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 229ms/step\n",
            "Predicted Class Label for /content/drive/MyDrive/Animal_Dataset/Birds/bird3.wav: Elephant\n"
          ]
        }
      ]
    }
  ]
}